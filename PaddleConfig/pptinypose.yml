#  Repositories : https://github.com/PaddlePaddle/PaddleDetection
#     Task type : KeyPoint Detection
# Preprocessing : object_detection_labelme2coco_keypoints.py
#   Base config : configs/keypoint/tiny_pose/tinypose_256x192.yml
#   Information : https://github.com/PaddlePaddle/PaddleDetection/blob/release/2.7/configs/keypoint/tiny_pose

### Before training
#   1. replace ${task_name} and ${config_name}
#   2. set _dataset_root
#   3. set num_joints
#   4. set _batch_size
#   5. set _learning_rate

### Start training （暂时不支持 --eval）
#   python3 -m paddle.distributed.launch tools/train.py -c data/${task_name}/${config_name}.yml

### Export inference model
#   python3 tools/export_model.py -c data/${task_name}/${config_name}.yml --output_dir workspace/${config_name}

### Test inference model
#   python3 deploy/python/det_keypoint_unite_infer.py --det_model_dir=workspace/inference/scale_det --keypoint_model_dir=workspace/inference/scale_pose --image_file=data/scale/src/baizijian/imgs/0000.jpg --device=GPU

########################################################################################
## dataset root
_dataset_root: &_dataset_root data/${task_name}/src

## number of key points
num_joints: &num_joints 5

## train batch size
_batch_size: &_batch_size 16

## base learning rate
# new_lr = (default_base_lr * batch_size * num_gpus) / (default_batch_size * default_num_gpus)
# new_lr = (0.002 * batch_size * num_gpus) / (128 * 4)
_learning_rate: &_learning_rate 0.00001

# 左右关键点经图像翻转时对应关系, 例如: 图像翻转后, 左手腕变成了右手腕, 右手腕变成了左手腕. 用于 flip 增强
flip_perm: &flip_perm []

use_gpu: true
log_iter: 20
snapshot_epoch: 30
epoch: 420
train_width: &train_width 192
train_height: &train_height 256
trainsize: &trainsize [*train_width, *train_height]
hmsize: &hmsize [48, 64]

## No need to follow
num_classes: 1
pixel_std: &pixel_std 200
metric: KeyPointTopDownCOCOEval
save_dir: workspace/${config_name}
weights: workspace/${config_name}/model_final.pdparams # 支持 --eval 后改为 best_model

#### >>>>> model <<<<< ######################################
architecture: TopDownHRNet
TopDownHRNet:
  backbone: LiteHRNet
  post_process: HRNetPostProcess
  flip_perm: *flip_perm
  num_joints: *num_joints
  width: &width 40
  loss: KeyPointMSELoss
  use_dark: true
LiteHRNet:
  network_type: wider_naive
  freeze_at: -1
  freeze_norm: false
  return_idx: [0]
KeyPointMSELoss:
  use_target_weight: true
  loss_scale: 1.0

#### >>>>> optimizer <<<<< ######################################
LearningRate:
  base_lr: *_learning_rate
  schedulers:
  - !PiecewiseDecay
    milestones: [380, 410]
    gamma: 0.1
  - !LinearWarmup
    start_factor: 0.001
    steps: 500
OptimizerBuilder:
  optimizer:
    type: Adam
  regularizer:
    factor: 0.0
    type: L2

#### >>>>> dataset <<<<< ######################################
TrainDataset:
  !KeypointTopDownCocoDataset
    image_dir: ""
    anno_path: pose_train.json
    dataset_dir: *_dataset_root
    num_joints: *num_joints
    trainsize: *trainsize
    pixel_std: *pixel_std
    use_gt_bbox: True
EvalDataset:
  !KeypointTopDownCocoDataset
    image_dir: ""
    anno_path: pose_test.json
    dataset_dir: *_dataset_root
    num_joints: *num_joints
    trainsize: *trainsize
    pixel_std: *pixel_std
    use_gt_bbox: True
    image_thre: 0.5
TestDataset:
  !ImageFolder
    anno_path: data/${task_name}/test_images.txt

#### >>>>> data loader <<<<< ######################################
worker_num: 8
global_mean: &global_mean [0.485, 0.456, 0.406]
global_std: &global_std [0.229, 0.224, 0.225]
TrainReader:
  sample_transforms:
    - RandomFlipHalfBodyTransform:
        scale: 0.25
        rot: 30
        num_joints_half_body: 0   # 半身关键点数量, 用于半身增强
        prob_half_body: 0         # 半身增强实现概率
        pixel_std: *pixel_std
        trainsize: *trainsize
        upper_body_ids: []        # 上半身对应关键点id, 用于半身增强中获取上半身对应的关键点
        flip_pairs: *flip_perm    # 关键点定义中左右对称的关键点，用于 flip 增强
        flip: False               # 关闭 flip 增强
    - AugmentationbyInformantionDropping:
        prob_cutout: 0.5
        offset_factor: 0.05
        num_patch: 1
        trainsize: *trainsize
    - TopDownAffine:
        trainsize: *trainsize
        use_udp: true
    - ToHeatmapsTopDown_DARK:
        hmsize: *hmsize
        sigma: 2
  batch_transforms:
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: *_batch_size
  shuffle: true
  drop_last: false

EvalReader:
  sample_transforms:
    - TopDownAffine:
        trainsize: *trainsize
        use_udp: true
  batch_transforms:
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 1

TestReader:
  inputs_def:
    image_shape: [3, *train_height, *train_width]
  sample_transforms:
    - Decode: {}
    - TopDownEvalAffine:
        trainsize: *trainsize
    - NormalizeImage:
        mean: *global_mean
        std: *global_std
        is_scale: true
    - Permute: {}
  batch_size: 1
  fuse_normalize: false
